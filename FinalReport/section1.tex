%%
%%  Department of Electrical, Electronic and Computer Engineering.
%%  EPR400/2 Final Report - Section 1.
%%  Copyright (C) 2011-2021 University of Pretoria.
%%

\section{Literature study}

The world is a vast and mysterious place, full obstacles, dynamic elements and unforeseen circumstances. Robots that have to navigate the world autonomously face a difficult and complex challenge, and require sophisticated solutions to address the uncertainty in sensor data, the danger of the environment and the comprehensive nature of the problem. Autonomous mapping and navigation of a UGV is the cornerstone of mobile robotics. Without a system capable of mapping the world and its location in it, as well as planning paths effectively, a robot relies on human interference
to move around.

\subsection{Positioning and Mapping}

A UGV has to create and maintain an internal representation of the world to navigate around and operate intelligently. The model needs to be at the right level of granularity to interpret the world accurately and efficiently. It consists of a map of the environment as well as an estimation of the robot's position and orientation in it, updated by a process called SLAM. \\

Various SLAM algorithms exists, among which Particle Filter (PF)-SLAM and Graph-SLAM are most prominent. Sugiura and Matsutani \cite{sugiura} investigates the performance of both methods during mapping. PF-SLAM estimates the map and robot position by distributing samples throughout the search space, which are weighted according to the degree of similarity between the sample's estimate of the environment and the sensor's measurement. Larger weights will propagate to the next sample, while smaller ones are removed. Graph-SLAM builds a node-graph while traversing the area, which optimizes the map around closed loops created upon arrival in a previously visited place. \\

An important aspect of both methods is the concept of scan-matching, where local maps built at different timesteps are compared to see if the map and position of the robot can be optimized in such a way that the maps correlate better. Sugiura and Matsutani interpret the map as a grid and evaluate four algorithms: Hill-Climbing, Gauss-Newton, CSM and Branch-and-Bound for optimization. The former two approaches are subject to local maxima, whereas the latter two are computationally expensive. The researchers finally implement CSM, starting with a coarse search map, which iteratively increases in granularity and decreases in size as the proximity of the optimal location is identified. \\

Zooming in on the mapping itself, there are many ways to model the map information obtained from the various sensors measurements, but it is important to choose a model that accurately describes the environment and facilitates quick and easy positioning and navigation. One implementation involves creating a quadtree, as proposed by Han et al. \cite{6393370}, which partitions the known environment into occupied and unoccupied blocks hierarchically, stopping at the coarsest resolution with a uniform occupancy state. This effectively reduces the memory required to store the map and can ease path planning calculations in some applications. \\

An alternative approach involves creating an occupancy map, either bit-wise, where "0" represents open and "1" represents blocked, or probabilistic, where each cell stores the probability that its area is occupied. Chen et al. \cite{9178471} describes a probabilistic occupancy grid map that undergoes optimization via a Bayes Filter.

\subsection{Navigation}

Autonomous navigation is a broad field, and many ingenious algorithms have been developed to address the challenge. The algorithms can be classified into two group according to their goal, in other words the objective that the method is trying to achieve. The first group aims to determine an optimal path to a certain position in a known environment. In essence, these methods try to plan a path to a certain position in the least amount of time and distance covered, without walking into obstacles. The second group of algorithms aim to maximize information gain in an unknown environment, exploring the landscape as efficiently as possible.  \\

A-star search, optimized for navigation in the paper by Ju et al. \cite{9296641}, is the most famous of the first group of path planning algorithms. A-star is a search algorithm with a heuristic, typically provided as the distance to the goal, and a cost, usually the distance travelled to the position, which tries to minimize the sum of the heuristic and the cost at each iteration. The algorithm always chooses the path with the lowest combined heuristic and cost and is thus optimal, even though complete knowledge of the relevant surroundings is needed. The paper adds an improvement to elegantly avoid obstacles similarly to how a human agent would, by heading towards to goal in a straight line while swerving around small obstacles. There is also potential to combine small sequential obstacles to form a larger obstacles that can be navigated more effectively. \\

A path planning algorithm that works on an entirely different principle is RRT. RRT and its improvement RRT*, is described by Chen et al. in \cite{8329210} as a a sampling-based alternative to the slower and more complex algebraic path planning methods. The algorithm randomly chooses the next location in the state space and proceeds in the location's direction by a set or varying amount, exploring new territory and evaluating if the goal has been reached. These class of algorithms are very simple to implement, and can be used in a wide variety of problems, due to the flexibility and generality of the approach. The methods also biases exploration into unknown domains, which helps to rapidly converge on a solution, if one exists. Whereas RRT connect the newly explored node to the geometrically closest node in a tree, the RRT* algorithm seeks to optimize the solution by joining nodes that correspond to the closest distance to that point from the origin. This will produce an optimal result as the number of nodes go to infinity, but suffers from increased complexity and computational burden. \\

The implementation specifically proposed in Chen's paper describes a novel adaptation to the dual tree RRT (DT-RRT), which constructs two trees, one starting at the state and one starting at the goal to simultaneously add nodes in the state space, aiming to converge on a solution sooner. Their paper not only combines dual trees with RRT* rewiring, but also samples in a Gaussian sampling cloud, which is dependent on the state of the system and the context of the problem. They also include methods to deal with boundary problems. This algorithm, being extremely sophisticated, will find use in large and complex path planning problems. \\

The second category of navigation algorithms focuses on exploration and maximizing information gain in the environment. Path planning in an unknown area is inherently more difficult than in known areas, but have seen a lot of research in the past two decades. Groundbreaking work was done by Yamauchi \cite{613851} on frontier-based exploration. He proposes an method that seeks to explore an unknown environment by identifying and moving towards areas of highest potential information gain. This is achieved by constructing an occupancy grid map of the environment, specifying open, unknown and obstructed areas. The frontiers between open and unknown spaces are identified and if a frontier has sufficient size, it will be explored by the robot. The algorithm makes room for dynamic obstacle avoidance in the case that the world changed a bit since the last visit, and will explore all reachable areas in time. \\

Despite the algorithms intuition and completeness appeal, the actual implementation is a lot more daunting. Between the map construction, frontier identification and path planning and obstacle avoidance to potential frontiers, this algorithm has a lot of loosely coupled components, each critical to the success of the operation. Calculating solutions analytically or using search algorithms are exhaustive and potentially burdensome. With this in mind Oriolo et al. \cite{1302457} divised a new method for exploring frontiers, with inspiration from the RRT approach, called Sensor-based Random Tree (SRT). \\

SRT uses the sensor measurements to construct a safe zone around the robot, either as a star, assuming accurate sensor readings in the respective directions, or as a ball, assuming inaccurate measurements and regarding only the closest distance to an obstacle. In either case, a random angle is selected together with a distance in that angle's direction near the edge of the safe zone to obtain a new candidate position node. The position is evaluated to verify that it is far enough away from the current position to justify the move and to make sure it does not fall within an already explored safe zone of a previously explored node. If the candidate fails these checks, a new candidate is chosen until the maximum allows attempts are exceeded, in which case the robot moves back to its parent node. This process ensures that the robot will continuously explore new areas until none are remaining, in which case the robot will return to its original starting position. \\

Combining the random sampling system first seen in RRT with the bias towards frontiers allows the SRT algorithm to implement a simple and effective sampling based exploration mechanism, capable of navigating an unknown environment intuitively with adjustable parameters depending on the sensor specifications of the robot. This makes SRT a simple and extremely flexible navigation tool with a wide range of possible uses and applications.

\subsection{Sensors}

To navigate around and interact with the environment intelligently, a UGV has to perceive the world sufficiently. Various types of sensors exist measuring various aspects of the environment at different accuracies, sample rates and costs. In mobile robotics it is often necessary to obtain information about the environment, such as the location of obstacles, as well as information about the robot itself, such as its measured speed or angular rate. Chan et al. \cite{8616217} recognizes the ubiquity of laser rangefinder in modern UGV systems, which maps the environment as a set of points to the nearest obstacle in a specific direction. The rangefinder is very accurate and its observation data can be used to reconstruct the world map quite effectively. \\

Another common sensor used for obstacle detectior is a monocular camera, first proposed as part of the LSD-SLAM method by Caruso et al. \cite{7353366}. Photos taken by a camera are extremely accurate and full of detail that can be used to reconstruct the environment precisely. The downside is that photos by themselves do not contain depth-information, so a simple analysis of the data do not yield useful results. Instead, the researchers design an intricate system of depth estimation Kalman filters, map optimization and context tracking across frames to analyse the input data. Not only is the process complex, but the photos themselves are large and obnoxious to work with. A laser rangefinder will output an array of distances to the nearest obstacle in the respective directions, totalling a few dozen data points at most. The photos in the paper, on the other hand, has a resolution of 480x480px, accumulating to 230400 data points arriving at 40 Hz. A system would require large computational and memory resources to deal with such a large influx of data. \\

Tracking the robots movement in the environment usually comes down to three sensors: IMUs, GPS and odometers. GPS navigation localizes a user on the ground using positioning data from nearby GPS satellites, and is extremely accurate. However these sensors only work well if there is a clear line of sight between the robot and the satellites, and is generally not suitable for use indoors. \\

IMUs contain a gyroscope, accelerometer in three dimensions, and often comes with a magnetometer as well, then known as a MARG sensor, enabling it to estimation orientation with high accuracy if a suitable filter is used to fuse to sensor data. Harindranath and Arora \cite{8904029} compare four commonly used filters to measure their statistical error and relative performance. Two statistical filters, the Extended Kalman Filter (EKF) and Two stage EKF (TKF-Q), as well as two non-statistical filters, the Mahony and Madgwick filters are compared. The paper aims to analyze the filters in different operating environments, simulating various levels of Gaussian noise, random walk bias and orientation pertubations. While the TKF-Q filter performed well in high levels of noise, the Mahony filters was the winner all around with the lowest average error for static and dynamic simulations with various levels of noise. This filter also benefits from fast execution times. \\

Odometers measure the rotation speed of the wheels attached to the motors, and can be used to determine distance travelled and orientation. Unfortunately wheels can slip, leading to inaccurate measurements, thus in general odometer data is fused with either IMU sensor data or corrected with environment perception optimization. Milijas et al. \cite{9129529} proposes an interactive SLAM-based algorithm, where laser rangefinders are used not only to obtain information of the environment but also to adjust for bad odometry, by viewing both sets of input data in the context of an optimization problem.

\newpage

%% End of File.


