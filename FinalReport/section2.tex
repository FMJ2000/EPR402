%%
%%  Department of Electrical, Electronic and Computer Engineering.
%%  EPR400/2 Final Report - Section 2.
%%  Copyright (C) 2011-2021 University of Pretoria.
%%

\section{Approach}

Designing and constructing an robotic vacuum cleaner capable of autonomous positioning, mapping, exploration and navigation is a rich and complex problem, with many subsystem that need to work together flawlessly for the end product to function. The first important step upon encountering such a large project is to set up a general roadmap and timeline for the design and implementation of the project. The roadmap starts out by evaluating the system requirements and identifies the main problems that the solution needs to address, which are autonomous navigation and floor cleaning in this case. 

These high-level abstract problems are systematically broken down to smaller and more tangible subsystems. Even though the cleaning is a core requirement of the project, it does not entail as much engineering as the navigation, as the project is aimed at computer and not mechanical engineering students, and thus relatively little has to be calculated and designed for the subsystem to function. Autonomous navigation, on the other hand, requires a holistic solution to the problem of robot positioning, mapping and navigation, each with its own sets of challenges and methods, working together in a complex dance. The subsystem's aim is to simultaneously allow the robot to perceive its environment to a sufficient degree that it can interact intelligently with it, and move around in a useful, timely and energy-efficient manner. 

Apart from the software design side, the system has a major hardware component as well. There is a need to identify components and design a layout that contains the necessary sensors, processing power and memory to achieve the goal and to integrate the parts efficiently so that it can be used in a mobile application. There is a bit of a design conundrum here, as the precise implementation of the software is dependent on the hardware components and the hardware requirements is dependent on the software perceived problems. This issue is addressed by identifying the high-level needs of the system software and thereafter searching for available and relevant hardware components (quite a challenge with the global supply chains disrupted). After the first few months of shopping and soldering the first iteration of the robot consisted of an chassis, motors and wheels, a H-bridge and a low-cost processor. 

Next, the basic startup firmware, including timers and peripheral drivers were implemented. The sensor peripherals used to measure distance, angular rate and wheel odometry are adding one-by-one and tested. The use of a Microchip PIC32 chip prohibited the use of standard functions as every single peripheral is initialized manually with register manipulation. This enables the system to run as efficiently as possible, only using exactly what it needs and how it needs it. Optimization of the available real estate on the robot leads to various iterations of the soldered veroboard in this time, with each iteration becoming smaller and using less pins. 

Finally the system is at the point where it can start interacting with the world. Although the software subsystem work together, there is a clear dependency hierarchy, as the mapping depends on accurate real-time positioning and the navigation depends on accurate, real-time mapping. Thus, these subsystems are mostly designed sequentially, iterating back to a previous step once a problem is uncovered. However, before implementation, it was discovered that these systems would be virtually impossible to test objectively using the current evaluation methods. As the reliance on large created data structures and measurement dependent parameters grow, there is no way of knowing why the robot reacts in the way it does without looking into its brain, which would be difficult with a wired serial connection. Instead an OLED screen and Bluetooth serial connection were added to navigate the thought process of the device. 

The positioning subsystem benefits from five sensor measurements: the accelerometer, gyroscope, magnetometer, right and left wheel odometers to update the state of the robot, which includes its position, relative to its internal Cartesian representation of the world. The perceived value and nature of each measurement is evaluated in an elaborate complementary filter. Starting from the systems own estimate of its state given its inputs, which are the PWM duty cycles of the wheels, the estimate is sequentially corrected by the measurements. This approach is favoured due to its simplicity and low computational requirements, whereas the abundance of sensor measurment data aims to bring balance into the equation.

The mapping subsystem faces the challenge of converting the range-based ultrasonic sensor data into an accurate enough representation of the environment so that the robot will not bump into obstacles and clean thoroughly. Three sensors give an idea of the distance to the nearest object in their respective directions, which are offset by $40^\circ$ around the front of the robot. The robot creates a probabilistic map of a certain $cm^2$ resolution to represent the world. Considering that the measurement data contains noise and cannot actually determine the position of an obstacle, just the distance to it in an certain wide field of view, the sequential incoming data is plotted on the probabilistic map as a multivariate Gaussian distribution, with the perceived obstacle positions as the means. Applying a highly efficient multiplication algorithm to the evolving map provides a simple and relatively low cost solution of the perception problem. Of course, there is no use in evaluating parts of the global map that is not currently in range, and thus a smaller local map is updated in the immediate area surrounding the robot. To save space, this probabilistic map is regularly saved back into the global map as a 2 bit-map, with the four values representing open (00), unknown (01), cleaned (10) and obstructed (11). This can be effectively utilized by the navigation algorithm to plan its trajectory.

The navigation subsystem has to use the robot's position and map to effectively explore the world, avoid bumping into obstacles and clean an area thoroughly. This is achieved by splitting the robot objectives into local and global groups. Local goals include calculating the immediate next position the robot has to move to in order to reach a global goal or avoid an obstacle. This algorithm uses a depth-first search scanning the surrounding map tiles for an open path, biasing towards front-facing, unexplored and uncleaned areas. Global goals usually entail following a certain pattern, such as an S-like or wall-following path around the room, but also has the capacity to detect areas missed during the preliminary cleaning cycle, which could happen in rooms with peculiar shapes and obstacles. The local navigation focuses on reaching the next few decimeters harmless, while the global planner focuses on the bigger picture, thoroughly sweeping a room. The use of specific Cartesian point destinations, instead of general directions, such as "go forward" or "turn left" for navigation allows for the precise control of the inputs to the motors depending on the error angle and destination to the desired location. This also generalizes the controller to follow its path, find its charging station and dodge obstacles with the same mechanics. \\



\newpage

